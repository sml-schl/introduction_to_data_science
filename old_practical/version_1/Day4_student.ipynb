{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3fada7c",
   "metadata": {},
   "source": [
    "# Day 4 — Student Notebook\n",
    "\n",
    "*Auto-generated notebook based on provided lecture slides.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993938d5",
   "metadata": {},
   "source": [
    "## Day 4 — Data Preparation & Feature Engineering\n",
    "**Goals:** understand data types, missing values, basic imputation, outlier detection, normalization, and one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ef51d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: installs (uncomment the !pip lines if needed) and imports\n",
    "# If running in a managed environment (e.g. Google Colab), uncomment the pip installs below.\n",
    "# !pip install pandas numpy seaborn plotly scikit-learn matplotlib\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "# Load dataset (seaborn's titanic dataset) - we'll use this across all notebooks\n",
    "df = sns.load_dataset('titanic')\n",
    "df_original = df.copy()  # keep a pristine copy\n",
    "print('Loaded titanic dataset with shape:', df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a346eb59",
   "metadata": {},
   "source": [
    "### 1) Inspect data types and convert if necessary\n",
    "- Check `df.dtypes`\n",
    "- Convert 'survived' to integer and 'pclass' to categorical if needed\n",
    "\n",
    "**Task:** perform conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c537140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student: inspect and convert\n",
    "df.dtypes\n",
    "# convert\n",
    "if df['survived'].dtype != 'int64' and df['survived'].dtype != 'int32':\n",
    "    df['survived'] = df['survived'].astype('int')\n",
    "if 'pclass' in df.columns:\n",
    "    df['pclass'] = df['pclass'].astype('category')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bff95d",
   "metadata": {},
   "source": [
    "### 2) Missing values handling\n",
    "- Identify columns with missing values\n",
    "- Try two strategies: drop rows with missing critical fields; imputing age with median\n",
    "\n",
    "**Tasks:**\n",
    "1. Show missing counts.\n",
    "2. Create `df_imputed` where `age` is imputed with median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student: missing value handling\n",
    "print(df.isna().sum())\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(strategy='median')\n",
    "df_imputed = df.copy()\n",
    "df_imputed['age'] = imp.fit_transform(df[['age']])\n",
    "print('Missing after impute (age):', df_imputed['age'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65b5f0b",
   "metadata": {},
   "source": [
    "### 3) Outlier detection (IQR) — student exercise\n",
    "- Use IQR method on 'fare'\n",
    "\n",
    "**Task:** Flag outliers in `fare` using 1.5*IQR rule and show count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d05827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student: IQR outlier detection\n",
    "q1 = df['fare'].quantile(0.25)\n",
    "q3 = df['fare'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower = q1 - 1.5*iqr\n",
    "upper = q3 + 1.5*iqr\n",
    "outliers = df[(df['fare']<lower) | (df['fare']>upper)]\n",
    "print('IQR bounds', lower, upper)\n",
    "print('Outlier count:', outliers.shape[0])\n",
    "outliers.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d352c10f",
   "metadata": {},
   "source": [
    "### 4) Normalization & encoding\n",
    "- Normalize numeric columns (age, fare) with MinMax and StandardScaler\n",
    "- One-hot encode 'sex' and 'embarked'\n",
    "\n",
    "**Task:** create a cleaned and encoded DataFrame `X_ready`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd90ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student: normalization & one-hot encoding\n",
    "num_cols = ['age','fare']\n",
    "X = df_imputed.copy()\n",
    "X[num_cols] = X[num_cols].fillna(X[num_cols].median())\n",
    "scaler = MinMaxScaler()\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "X = pd.get_dummies(X, columns=['sex','embarked'], drop_first=True)\n",
    "print('Columns after encoding:', X.columns.tolist()[:20])\n",
    "X_ready = X\n",
    "X_ready.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0b496e",
   "metadata": {},
   "source": [
    "### Short reflection\n",
    "- Why do we normalize numeric features for some models?\n",
    "- When is one-hot encoding necessary? Write a one-paragraph answer."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
