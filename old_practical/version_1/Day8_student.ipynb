{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab1b17a6",
   "metadata": {},
   "source": [
    "# Day 8 — Student Notebook\n",
    "\n",
    "*Auto-generated notebook based on provided lecture slides.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d704a052",
   "metadata": {},
   "source": [
    "## Day 8 — Model Evaluation & Exam-style practice\n",
    "**Goals:** learn common metrics (precision, recall, f1, ROC-AUC), cross-validation, and overfitting/underfitting intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64fc2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: installs (uncomment the !pip lines if needed) and imports\n",
    "# If running in a managed environment (e.g. Google Colab), uncomment the pip installs below.\n",
    "# !pip install pandas numpy seaborn plotly scikit-learn matplotlib\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "# Load dataset (seaborn's titanic dataset) - we'll use this across all notebooks\n",
    "df = sns.load_dataset('titanic')\n",
    "df_original = df.copy()  # keep a pristine copy\n",
    "print('Loaded titanic dataset with shape:', df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263663ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data quickly\n",
    "df_ml = df.copy()\n",
    "df_ml['age'] = df_ml['age'].fillna(df_ml['age'].median())\n",
    "df_ml['fare'] = df_ml['fare'].fillna(df_ml['fare'].median())\n",
    "df_ml = pd.get_dummies(df_ml, columns=['sex','embarked','class'], drop_first=True)\n",
    "features = ['age','fare'] + [c for c in df_ml.columns if c.startswith('sex_') or c.startswith('embarked_') or c.startswith('class_')]\n",
    "X = df_ml[features]\n",
    "y = df_ml['survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit a model\n",
    "clf = LogisticRegression(max_iter=300)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c6e7b",
   "metadata": {},
   "source": [
    "### 1) Compute evaluation metrics (student)\n",
    "- Accuracy, precision, recall, f1\n",
    "- Confusion matrix\n",
    "- ROC AUC and plot ROC curve\n",
    "\n",
    "**Task:** compute and interpret these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c537b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student: metrics\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))\n",
    "print('ROC AUC:', roc_auc_score(y_test, y_proba))\n",
    "\n",
    "# ROC curve data\n",
    "fpr, tpr, thr = roc_curve(y_test, y_proba)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f0821e",
   "metadata": {},
   "source": [
    "### 2) Cross-validation (student)\n",
    "- Use `cross_val_score` to estimate average accuracy with 5-fold CV\n",
    "\n",
    "**Task:** compute 5-fold cross-validated accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c02c35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "print('5-fold accuracy scores:', scores)\n",
    "print('Mean accuracy:', np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fabed86",
   "metadata": {},
   "source": [
    "### 3) Over/underfitting demo (student)\n",
    "- Train KNN with k from 1 to 20 and plot train vs test accuracy to see bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f50281",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "ks = list(range(1,21))\n",
    "for k in ks:\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_scores.append(model.score(X_train, y_train))\n",
    "    test_scores.append(model.score(X_test, y_test))\n",
    "\n",
    "plt.plot(ks, train_scores, label='train')\n",
    "plt.plot(ks, test_scores, label='test')\n",
    "plt.xlabel('k (neighbors)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('KNN: train vs test accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6babbb",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "- Where is overfitting visible? How would you choose k? What other steps reduce overfitting?"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
