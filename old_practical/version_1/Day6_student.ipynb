{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d06d734",
   "metadata": {},
   "source": [
    "# Day 6 — Student Notebook\n",
    "\n",
    "*Auto-generated notebook based on provided lecture slides.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa107e53",
   "metadata": {},
   "source": [
    "## Day 6 — Introduction to Machine Learning\n",
    "**Goals:** understand supervised vs unsupervised, train/test split, train a simple classifier (logistic regression, KNN) on the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff8f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: installs (uncomment the !pip lines if needed) and imports\n",
    "# If running in a managed environment (e.g. Google Colab), uncomment the pip installs below.\n",
    "# !pip install pandas numpy seaborn plotly scikit-learn matplotlib\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "# Load dataset (seaborn's titanic dataset) - we'll use this across all notebooks\n",
    "df = sns.load_dataset('titanic')\n",
    "df_original = df.copy()  # keep a pristine copy\n",
    "print('Loaded titanic dataset with shape:', df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e4631",
   "metadata": {},
   "source": [
    "### 1) Prepare data for supervised learning\n",
    "- Predict `survived` using a small set of features: `pclass`, `sex`, `age`, `fare`, `embarked`.\n",
    "- Use median imputation + simple encoding.\n",
    "\n",
    "**Task:** create `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbf2d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student: create X and y\n",
    "df_ml = df.copy()\n",
    "# simple preprocessing\n",
    "df_ml['age'] = df_ml['age'].fillna(df_ml['age'].median())\n",
    "df_ml['fare'] = df_ml['fare'].fillna(df_ml['fare'].median())\n",
    "df_ml = pd.get_dummies(df_ml, columns=['sex','embarked','class'], drop_first=True)\n",
    "features = ['age','fare'] + [c for c in df_ml.columns if c.startswith('sex_') or c.startswith('embarked_') or c.startswith('class_')]\n",
    "X = df_ml[features]\n",
    "y = df_ml['survived']\n",
    "print('Features used:', features)\n",
    "print('Shape X,y:', X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebdb0b4",
   "metadata": {},
   "source": [
    "### 2) Train/test split and a baseline model (student)\n",
    "- Split data (80/20)\n",
    "- Train LogisticRegression\n",
    "- Evaluate accuracy\n",
    "\n",
    "**Task:** implement train/test split and fit logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student: train/test + logistic regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = LogisticRegression(max_iter=200)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f23f7b",
   "metadata": {},
   "source": [
    "### 3) Try K-Nearest Neighbors (student)\n",
    "- Train KNN with k=5 and compare accuracy\n",
    "\n",
    "**Task:** fit KNN and compare results to logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc6c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student: KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print('KNN Accuracy:', accuracy_score(y_test, y_pred_knn))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a181fbac",
   "metadata": {},
   "source": [
    "### Short reflection\n",
    "- Which model performed better? Why might that be the case?\n",
    "- What are weaknesses of these simple approaches?"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
