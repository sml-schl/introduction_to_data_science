{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Day 6 - Introduction to Machine Learning: Complete Solutions\n",
    "\n",
    "**Comprehensive Solutions Notebook**\n",
    "\n",
    "This notebook provides complete solutions for all Day 6 exercises including:\n",
    "- Train-test split implementation with best practices\n",
    "- Multiple classification algorithms (KNN, Decision Trees, Logistic Regression)\n",
    "- Regression analysis (Linear Regression for fare prediction)\n",
    "- Unsupervised learning (K-means clustering)\n",
    "- Neural network concepts and examples\n",
    "- Comprehensive visualizations and model comparisons\n",
    "- Performance metrics and evaluation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import all necessary libraries and configure our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation commands (uncomment if needed)\n",
    "# !pip install pandas numpy seaborn plotly scikit-learn matplotlib\n",
    "\n",
    "# Core data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Classification algorithms\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    roc_auc_score, roc_curve, auc,\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    silhouette_score\n",
    ")\n",
    "\n",
    "# Neural network (for conceptual examples)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Configuration\n",
    "sns.set_theme(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-header",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration\n",
    "\n",
    "We'll use the famous Titanic dataset to demonstrate machine learning concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "df_original = df.copy()  # Keep pristine copy for reference\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-info",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed information about the dataset\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\"*60)\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Missing Values Summary:\")\n",
    "print(\"=\"*60)\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing Count': df.isnull().sum(),\n",
    "    'Missing Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "print(missing_data[missing_data['Missing Count'] > 0].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Target Variable Distribution (Survived):\")\n",
    "print(\"=\"*60)\n",
    "print(df['survived'].value_counts())\n",
    "print(f\"\\nSurvival Rate: {df['survived'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ml-concepts-header",
   "metadata": {},
   "source": [
    "## 2. Machine Learning Concepts\n",
    "\n",
    "### Supervised vs. Unsupervised Learning\n",
    "\n",
    "**Supervised Learning:**\n",
    "- We have labeled data (input features + target variable)\n",
    "- Goal: Learn a mapping from inputs to outputs\n",
    "- Examples: Classification (predicting survival), Regression (predicting fare)\n",
    "\n",
    "**Unsupervised Learning:**\n",
    "- We have unlabeled data (only input features)\n",
    "- Goal: Discover patterns or structure in the data\n",
    "- Examples: Clustering (grouping similar passengers), Dimensionality Reduction\n",
    "\n",
    "### The ML Workflow\n",
    "\n",
    "1. **Data Preparation**: Clean, transform, and engineer features\n",
    "2. **Train-Test Split**: Separate data for training and evaluation\n",
    "3. **Model Training**: Fit the model on training data\n",
    "4. **Model Evaluation**: Assess performance on test data\n",
    "5. **Model Comparison**: Compare multiple models\n",
    "6. **Hyperparameter Tuning**: Optimize model parameters\n",
    "7. **Deployment**: Use the model for predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing-header",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing for Supervised Learning\n",
    "\n",
    "**Best Practices:**\n",
    "- Handle missing values systematically\n",
    "- Encode categorical variables appropriately\n",
    "- Scale numerical features when necessary\n",
    "- Create meaningful features from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocessing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a working copy for machine learning\n",
    "df_ml = df.copy()\n",
    "\n",
    "print(\"Data Preprocessing Steps:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 1: Handle missing values\n",
    "print(\"\\n1. Handling Missing Values:\")\n",
    "print(\"   - Age: Filling with median\")\n",
    "df_ml['age'] = df_ml['age'].fillna(df_ml['age'].median())\n",
    "\n",
    "print(\"   - Fare: Filling with median\")\n",
    "df_ml['fare'] = df_ml['fare'].fillna(df_ml['fare'].median())\n",
    "\n",
    "print(\"   - Embarked: Filling with mode (most common value)\")\n",
    "df_ml['embarked'] = df_ml['embarked'].fillna(df_ml['embarked'].mode()[0])\n",
    "\n",
    "# Step 2: Feature engineering\n",
    "print(\"\\n2. Feature Engineering:\")\n",
    "print(\"   - Creating 'family_size' from sibsp and parch\")\n",
    "df_ml['family_size'] = df_ml['sibsp'] + df_ml['parch'] + 1\n",
    "\n",
    "print(\"   - Creating 'is_alone' indicator\")\n",
    "df_ml['is_alone'] = (df_ml['family_size'] == 1).astype(int)\n",
    "\n",
    "print(\"   - Creating age groups\")\n",
    "df_ml['age_group'] = pd.cut(df_ml['age'], \n",
    "                              bins=[0, 12, 18, 35, 60, 100], \n",
    "                              labels=['Child', 'Teen', 'Adult', 'Middle_Age', 'Senior'])\n",
    "\n",
    "# Step 3: Encode categorical variables\n",
    "print(\"\\n3. Encoding Categorical Variables:\")\n",
    "print(\"   - Using one-hot encoding for: sex, embarked, class, age_group\")\n",
    "df_ml = pd.get_dummies(df_ml, columns=['sex', 'embarked', 'class', 'age_group'], drop_first=True)\n",
    "\n",
    "# Step 4: Select features for modeling\n",
    "print(\"\\n4. Feature Selection:\")\n",
    "feature_cols = ['age', 'fare', 'family_size', 'is_alone'] + \\\n",
    "               [c for c in df_ml.columns if c.startswith(('sex_', 'embarked_', 'class_', 'age_group_'))]\n",
    "\n",
    "X = df_ml[feature_cols]\n",
    "y = df_ml['survived']\n",
    "\n",
    "print(f\"\\nFinal feature set: {len(feature_cols)} features\")\n",
    "print(f\"Features: {feature_cols}\")\n",
    "print(f\"\\nX shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-test-header",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split Implementation\n",
    "\n",
    "**Why Split Data?**\n",
    "- Training set: Used to train the model\n",
    "- Test set: Used to evaluate model performance on unseen data\n",
    "- Prevents overfitting and provides realistic performance estimates\n",
    "\n",
    "**Best Practices:**\n",
    "- Typical split: 80/20 or 70/30 (train/test)\n",
    "- Use stratification for imbalanced datasets\n",
    "- Set random_state for reproducibility\n",
    "- Never look at test data during training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-test-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,        # 20% for testing\n",
    "    random_state=42,      # For reproducibility\n",
    "    stratify=y            # Maintain class distribution\n",
    ")\n",
    "\n",
    "print(\"Train-Test Split Results:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training set size: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"Survival rate: {y_train.mean():.2%}\")\n",
    "\n",
    "print(\"\\nClass distribution in test set:\")\n",
    "print(y_test.value_counts())\n",
    "print(f\"Survival rate: {y_test.mean():.2%}\")\n",
    "\n",
    "# Optional: Scale features (important for some algorithms like KNN)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for easier handling\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"\\nFeatures scaled using StandardScaler (mean=0, std=1)\")\n",
    "print(\"\\nTraining Features Summary:\")\n",
    "print(X_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classification-header",
   "metadata": {},
   "source": [
    "## 5. Classification Models\n",
    "\n",
    "We'll implement and compare multiple classification algorithms:\n",
    "1. **Logistic Regression**: Linear model for binary classification\n",
    "2. **K-Nearest Neighbors (KNN)**: Instance-based learning\n",
    "3. **Decision Tree**: Tree-based model with interpretable rules\n",
    "4. **Random Forest**: Ensemble of decision trees\n",
    "5. **Neural Network**: Multi-layer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logistic-header",
   "metadata": {},
   "source": [
    "### 5.1 Logistic Regression\n",
    "\n",
    "**When to use:**\n",
    "- Binary or multi-class classification\n",
    "- Need interpretable coefficients\n",
    "- Assume linear relationship between features and log-odds of target\n",
    "\n",
    "**Advantages:**\n",
    "- Fast training and prediction\n",
    "- Probabilistic predictions\n",
    "- Good baseline model\n",
    "\n",
    "**Disadvantages:**\n",
    "- Assumes linear decision boundary\n",
    "- May underfit complex patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logistic-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression model\n",
    "print(\"Training Logistic Regression Model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    solver='lbfgs'\n",
    ")\n",
    "\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate model\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr)\n",
    "recall_lr = recall_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "roc_auc_lr = roc_auc_score(y_test, y_pred_proba_lr)\n",
    "\n",
    "print(f\"\\nLogistic Regression Performance:\")\n",
    "print(f\"  Accuracy:  {accuracy_lr:.4f}\")\n",
    "print(f\"  Precision: {precision_lr:.4f}\")\n",
    "print(f\"  Recall:    {recall_lr:.4f}\")\n",
    "print(f\"  F1 Score:  {f1_lr:.4f}\")\n",
    "print(f\"  ROC AUC:   {roc_auc_lr:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "print(cm_lr)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['Not Survived', 'Survived']))\n",
    "\n",
    "# Feature importance (coefficients)\n",
    "print(\"\\nTop 10 Most Important Features (by absolute coefficient):\")\n",
    "feature_importance_lr = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': lr_model.coef_[0]\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "print(feature_importance_lr.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knn-header",
   "metadata": {},
   "source": [
    "### 5.2 K-Nearest Neighbors (KNN)\n",
    "\n",
    "**How it works:**\n",
    "- Finds K nearest training examples to a test point\n",
    "- Predicts based on majority vote of neighbors\n",
    "- Distance metric: Usually Euclidean distance\n",
    "\n",
    "**When to use:**\n",
    "- Non-linear decision boundaries\n",
    "- Small to medium datasets\n",
    "- Data is properly scaled\n",
    "\n",
    "**Advantages:**\n",
    "- Simple and intuitive\n",
    "- No training phase (lazy learning)\n",
    "- Can handle complex patterns\n",
    "\n",
    "**Disadvantages:**\n",
    "- Slow prediction on large datasets\n",
    "- Sensitive to feature scaling\n",
    "- Curse of dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knn-classifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train KNN model\n",
    "print(\"Training K-Nearest Neighbors Model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "knn_model = KNeighborsClassifier(\n",
    "    n_neighbors=5,\n",
    "    weights='uniform',  # All neighbors weighted equally\n",
    "    metric='euclidean'\n",
    ")\n",
    "\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "y_pred_proba_knn = knn_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "precision_knn = precision_score(y_test, y_pred_knn)\n",
    "recall_knn = recall_score(y_test, y_pred_knn)\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "roc_auc_knn = roc_auc_score(y_test, y_pred_proba_knn)\n",
    "\n",
    "print(f\"\\nK-Nearest Neighbors Performance (k=5):\")\n",
    "print(f\"  Accuracy:  {accuracy_knn:.4f}\")\n",
    "print(f\"  Precision: {precision_knn:.4f}\")\n",
    "print(f\"  Recall:    {recall_knn:.4f}\")\n",
    "print(f\"  F1 Score:  {f1_knn:.4f}\")\n",
    "print(f\"  ROC AUC:   {roc_auc_knn:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "print(cm_knn)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn, target_names=['Not Survived', 'Survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knn-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal K value\n",
    "print(\"Finding Optimal K Value...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "k_values = range(1, 31)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    train_scores.append(knn.score(X_train_scaled, y_train))\n",
    "    test_scores.append(knn.score(X_test_scaled, y_test))\n",
    "\n",
    "# Find best K\n",
    "best_k = k_values[np.argmax(test_scores)]\n",
    "best_score = max(test_scores)\n",
    "\n",
    "print(f\"\\nOptimal K: {best_k}\")\n",
    "print(f\"Best Test Accuracy: {best_score:.4f}\")\n",
    "\n",
    "# Create visualization\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=list(k_values), y=train_scores, mode='lines+markers', name='Training Accuracy'))\n",
    "fig.add_trace(go.Scatter(x=list(k_values), y=test_scores, mode='lines+markers', name='Test Accuracy'))\n",
    "fig.add_vline(x=best_k, line_dash=\"dash\", line_color=\"red\", annotation_text=f\"Optimal K={best_k}\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='KNN Performance vs K Value',\n",
    "    xaxis_title='K (Number of Neighbors)',\n",
    "    yaxis_title='Accuracy',\n",
    "    hovermode='x unified',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Retrain with optimal K\n",
    "knn_optimal = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_optimal.fit(X_train_scaled, y_train)\n",
    "y_pred_knn_optimal = knn_optimal.predict(X_test_scaled)\n",
    "accuracy_knn_optimal = accuracy_score(y_test, y_pred_knn_optimal)\n",
    "\n",
    "print(f\"\\nOptimized KNN Accuracy: {accuracy_knn_optimal:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decision-tree-header",
   "metadata": {},
   "source": [
    "### 5.3 Decision Tree Classifier\n",
    "\n",
    "**How it works:**\n",
    "- Creates a tree of if-then-else decision rules\n",
    "- Splits data based on feature values\n",
    "- Each leaf node represents a class prediction\n",
    "\n",
    "**When to use:**\n",
    "- Need interpretable model\n",
    "- Non-linear relationships\n",
    "- Mixed feature types (numerical and categorical)\n",
    "\n",
    "**Advantages:**\n",
    "- Highly interpretable\n",
    "- Handles non-linear patterns\n",
    "- No need for feature scaling\n",
    "- Can handle missing values\n",
    "\n",
    "**Disadvantages:**\n",
    "- Prone to overfitting\n",
    "- Unstable (small data changes can cause large tree changes)\n",
    "- Biased toward features with many levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decision-tree",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree model\n",
    "print(\"Training Decision Tree Classifier...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=5,           # Limit depth to prevent overfitting\n",
    "    min_samples_split=20,  # Minimum samples required to split\n",
    "    min_samples_leaf=10,   # Minimum samples required at leaf node\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt_model.fit(X_train, y_train)  # No scaling needed for trees\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "y_pred_proba_dt = dt_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt)\n",
    "recall_dt = recall_score(y_test, y_pred_dt)\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "roc_auc_dt = roc_auc_score(y_test, y_pred_proba_dt)\n",
    "\n",
    "print(f\"\\nDecision Tree Performance:\")\n",
    "print(f\"  Accuracy:  {accuracy_dt:.4f}\")\n",
    "print(f\"  Precision: {precision_dt:.4f}\")\n",
    "print(f\"  Recall:    {recall_dt:.4f}\")\n",
    "print(f\"  F1 Score:  {f1_dt:.4f}\")\n",
    "print(f\"  ROC AUC:   {roc_auc_dt:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "print(cm_dt)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt, target_names=['Not Survived', 'Survived']))\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "feature_importance_dt = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': dt_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "print(feature_importance_dt.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tree-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Decision Tree\n",
    "print(\"Decision Tree Visualization:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(\n",
    "    dt_model, \n",
    "    feature_names=X_train.columns,\n",
    "    class_names=['Not Survived', 'Survived'],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10\n",
    ")\n",
    "plt.title('Decision Tree Structure', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance bar chart\n",
    "fig = px.bar(\n",
    "    feature_importance_dt.head(10),\n",
    "    x='Importance',\n",
    "    y='Feature',\n",
    "    orientation='h',\n",
    "    title='Top 10 Feature Importances - Decision Tree',\n",
    "    labels={'Importance': 'Feature Importance', 'Feature': ''},\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.update_layout(yaxis={'categoryorder': 'total ascending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-network-header",
   "metadata": {},
   "source": [
    "### 5.4 Neural Network (Multi-Layer Perceptron)\n",
    "\n",
    "**How it works:**\n",
    "- Multiple layers of interconnected neurons\n",
    "- Each connection has a weight that's learned during training\n",
    "- Uses backpropagation to update weights\n",
    "\n",
    "**When to use:**\n",
    "- Complex non-linear patterns\n",
    "- Large datasets\n",
    "- High-dimensional data\n",
    "\n",
    "**Advantages:**\n",
    "- Can learn very complex patterns\n",
    "- Flexible architecture\n",
    "- State-of-the-art for many problems\n",
    "\n",
    "**Disadvantages:**\n",
    "- Requires large amounts of data\n",
    "- Computationally expensive\n",
    "- Black box (hard to interpret)\n",
    "- Many hyperparameters to tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Neural Network model\n",
    "print(\"Training Neural Network (Multi-Layer Perceptron)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50),  # Two hidden layers with 100 and 50 neurons\n",
    "    activation='relu',              # ReLU activation function\n",
    "    solver='adam',                  # Adam optimizer\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    early_stopping=True,            # Stop when validation score stops improving\n",
    "    validation_fraction=0.1\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_nn = nn_model.predict(X_test_scaled)\n",
    "y_pred_proba_nn = nn_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate model\n",
    "accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
    "precision_nn = precision_score(y_test, y_pred_nn)\n",
    "recall_nn = recall_score(y_test, y_pred_nn)\n",
    "f1_nn = f1_score(y_test, y_pred_nn)\n",
    "roc_auc_nn = roc_auc_score(y_test, y_pred_proba_nn)\n",
    "\n",
    "print(f\"\\nNeural Network Performance:\")\n",
    "print(f\"  Accuracy:  {accuracy_nn:.4f}\")\n",
    "print(f\"  Precision: {precision_nn:.4f}\")\n",
    "print(f\"  Recall:    {recall_nn:.4f}\")\n",
    "print(f\"  F1 Score:  {f1_nn:.4f}\")\n",
    "print(f\"  ROC AUC:   {roc_auc_nn:.4f}\")\n",
    "\n",
    "print(f\"\\nNetwork Architecture:\")\n",
    "print(f\"  Input Layer: {X_train.shape[1]} features\")\n",
    "print(f\"  Hidden Layer 1: 100 neurons\")\n",
    "print(f\"  Hidden Layer 2: 50 neurons\")\n",
    "print(f\"  Output Layer: 2 classes (binary)\")\n",
    "print(f\"  Total Iterations: {nn_model.n_iter_}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm_nn = confusion_matrix(y_test, y_pred_nn)\n",
    "print(cm_nn)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_nn, target_names=['Not Survived', 'Survived']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-comparison-header",
   "metadata": {},
   "source": [
    "## 6. Model Comparison and Visualization\n",
    "\n",
    "Let's compare all classification models side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison DataFrame\n",
    "model_comparison = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'KNN (k=5)', f'KNN (k={best_k})', 'Decision Tree', 'Neural Network'],\n",
    "    'Accuracy': [accuracy_lr, accuracy_knn, accuracy_knn_optimal, accuracy_dt, accuracy_nn],\n",
    "    'Precision': [precision_lr, precision_knn, precision_score(y_test, y_pred_knn_optimal), precision_dt, precision_nn],\n",
    "    'Recall': [recall_lr, recall_knn, recall_score(y_test, y_pred_knn_optimal), recall_dt, recall_nn],\n",
    "    'F1 Score': [f1_lr, f1_knn, f1_score(y_test, y_pred_knn_optimal), f1_dt, f1_nn],\n",
    "    'ROC AUC': [roc_auc_lr, roc_auc_knn, roc_auc_score(y_test, knn_optimal.predict_proba(X_test_scaled)[:, 1]), roc_auc_dt, roc_auc_nn]\n",
    "})\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(\"=\"*80)\n",
    "print(model_comparison.to_string(index=False))\n",
    "\n",
    "# Identify best model for each metric\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Best Model by Metric:\")\n",
    "print(\"=\"*80)\n",
    "for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']:\n",
    "    best_idx = model_comparison[metric].idxmax()\n",
    "    best_model = model_comparison.loc[best_idx, 'Model']\n",
    "    best_value = model_comparison.loc[best_idx, metric]\n",
    "    print(f\"{metric:12s}: {best_model:25s} ({best_value:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visual comparison\n",
    "metrics_for_plot = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for idx, model_name in enumerate(model_comparison['Model']):\n",
    "    values = model_comparison.iloc[idx][metrics_for_plot].values\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=values,\n",
    "        theta=metrics_for_plot,\n",
    "        name=model_name,\n",
    "        fill='toself'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0.5, 1.0]\n",
    "        )\n",
    "    ),\n",
    "    title='Model Performance Comparison - All Metrics',\n",
    "    showlegend=True,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Bar chart comparison\n",
    "fig = px.bar(\n",
    "    model_comparison,\n",
    "    x='Model',\n",
    "    y=['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    title='Model Performance Metrics Comparison',\n",
    "    barmode='group',\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.update_layout(yaxis_title='Score', legend_title='Metric')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confusion-matrices",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrices for all models\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Confusion Matrices - All Models', fontsize=16, fontweight='bold')\n",
    "\n",
    "confusion_matrices = [\n",
    "    (cm_lr, 'Logistic Regression', accuracy_lr),\n",
    "    (cm_knn, 'KNN (k=5)', accuracy_knn),\n",
    "    (confusion_matrix(y_test, y_pred_knn_optimal), f'KNN (k={best_k})', accuracy_knn_optimal),\n",
    "    (cm_dt, 'Decision Tree', accuracy_dt),\n",
    "    (cm_nn, 'Neural Network', accuracy_nn)\n",
    "]\n",
    "\n",
    "for idx, (cm, title, acc) in enumerate(confusion_matrices):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, \n",
    "                xticklabels=['Not Survived', 'Survived'],\n",
    "                yticklabels=['Not Survived', 'Survived'])\n",
    "    ax.set_title(f'{title}\\nAccuracy: {acc:.4f}', fontweight='bold')\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "\n",
    "# Hide unused subplot\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roc-curves",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves for all models\n",
    "fig = go.Figure()\n",
    "\n",
    "# Calculate ROC curve for each model\n",
    "models_roc = [\n",
    "    ('Logistic Regression', y_pred_proba_lr, roc_auc_lr),\n",
    "    ('KNN (k=5)', y_pred_proba_knn, roc_auc_knn),\n",
    "    (f'KNN (k={best_k})', knn_optimal.predict_proba(X_test_scaled)[:, 1], roc_auc_score(y_test, knn_optimal.predict_proba(X_test_scaled)[:, 1])),\n",
    "    ('Decision Tree', y_pred_proba_dt, roc_auc_dt),\n",
    "    ('Neural Network', y_pred_proba_nn, roc_auc_nn)\n",
    "]\n",
    "\n",
    "for model_name, y_proba, auc_score in models_roc:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=fpr, y=tpr,\n",
    "        mode='lines',\n",
    "        name=f'{model_name} (AUC={auc_score:.3f})'\n",
    "    ))\n",
    "\n",
    "# Add diagonal reference line\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 1], y=[0, 1],\n",
    "    mode='lines',\n",
    "    name='Random Classifier',\n",
    "    line=dict(dash='dash', color='gray')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='ROC Curves - All Models',\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    template='plotly_white',\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regression-header",
   "metadata": {},
   "source": [
    "## 7. Regression Analysis: Predicting Fare\n",
    "\n",
    "**Regression vs Classification:**\n",
    "- Classification: Predict discrete categories (survived/not survived)\n",
    "- Regression: Predict continuous values (fare price)\n",
    "\n",
    "**Linear Regression:**\n",
    "- Assumes linear relationship between features and target\n",
    "- Fits a line (or hyperplane) to minimize squared errors\n",
    "- Fast and interpretable\n",
    "\n",
    "**Evaluation Metrics:**\n",
    "- **MSE (Mean Squared Error)**: Average squared difference between predictions and actual values\n",
    "- **MAE (Mean Absolute Error)**: Average absolute difference\n",
    "- **R² Score**: Proportion of variance explained by the model (0 to 1, higher is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regression-prep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for regression (predicting fare)\n",
    "print(\"Preparing Data for Fare Prediction (Regression)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Use original dataframe\n",
    "df_reg = df_original.copy()\n",
    "\n",
    "# Remove rows with missing fare\n",
    "df_reg = df_reg.dropna(subset=['fare'])\n",
    "\n",
    "# Feature engineering\n",
    "df_reg['age'] = df_reg['age'].fillna(df_reg['age'].median())\n",
    "df_reg['family_size'] = df_reg['sibsp'] + df_reg['parch'] + 1\n",
    "df_reg['is_alone'] = (df_reg['family_size'] == 1).astype(int)\n",
    "\n",
    "# Encode categorical variables\n",
    "df_reg = pd.get_dummies(df_reg, columns=['sex', 'embarked', 'class'], drop_first=True)\n",
    "\n",
    "# Select features (exclude fare)\n",
    "feature_cols_reg = ['age', 'sibsp', 'parch', 'family_size', 'is_alone', 'survived'] + \\\n",
    "                   [c for c in df_reg.columns if c.startswith(('sex_', 'embarked_', 'class_'))]\n",
    "\n",
    "X_reg = df_reg[feature_cols_reg]\n",
    "y_reg = df_reg['fare']\n",
    "\n",
    "print(f\"Dataset shape: {X_reg.shape}\")\n",
    "print(f\"\\nTarget variable (Fare) statistics:\")\n",
    "print(y_reg.describe())\n",
    "\n",
    "# Train-test split\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler_reg = StandardScaler()\n",
    "X_train_reg_scaled = scaler_reg.fit_transform(X_train_reg)\n",
    "X_test_reg_scaled = scaler_reg.transform(X_test_reg)\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train_reg.shape[0]}\")\n",
    "print(f\"Test set size: {X_test_reg.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression model\n",
    "print(\"Training Linear Regression Model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lr_reg_model = LinearRegression()\n",
    "lr_reg_model.fit(X_train_reg_scaled, y_train_reg)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train_reg = lr_reg_model.predict(X_train_reg_scaled)\n",
    "y_pred_test_reg = lr_reg_model.predict(X_test_reg_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "train_mse = mean_squared_error(y_train_reg, y_pred_train_reg)\n",
    "test_mse = mean_squared_error(y_test_reg, y_pred_test_reg)\n",
    "train_mae = mean_absolute_error(y_train_reg, y_pred_train_reg)\n",
    "test_mae = mean_absolute_error(y_test_reg, y_pred_test_reg)\n",
    "train_r2 = r2_score(y_train_reg, y_pred_train_reg)\n",
    "test_r2 = r2_score(y_test_reg, y_pred_test_reg)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print(\"\\nLinear Regression Performance:\")\n",
    "print(\"=\"*60)\n",
    "print(\"Training Set:\")\n",
    "print(f\"  RMSE (Root Mean Squared Error): ${train_rmse:.2f}\")\n",
    "print(f\"  MAE (Mean Absolute Error):      ${train_mae:.2f}\")\n",
    "print(f\"  R² Score:                       {train_r2:.4f}\")\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"  RMSE (Root Mean Squared Error): ${test_rmse:.2f}\")\n",
    "print(f\"  MAE (Mean Absolute Error):      ${test_mae:.2f}\")\n",
    "print(f\"  R² Score:                       {test_r2:.4f}\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"  - On average, predictions are off by ${test_mae:.2f} (MAE)\")\n",
    "print(f\"  - Model explains {test_r2:.1%} of variance in fare prices (R²)\")\n",
    "\n",
    "# Feature coefficients\n",
    "print(\"\\nTop 10 Features Affecting Fare (by absolute coefficient):\")\n",
    "feature_coef = pd.DataFrame({\n",
    "    'Feature': X_reg.columns,\n",
    "    'Coefficient': lr_reg_model.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "print(feature_coef.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regression-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regression results\n",
    "\n",
    "# 1. Predicted vs Actual values\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Training Set', 'Test Set')\n",
    ")\n",
    "\n",
    "# Training set\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_train_reg, y=y_pred_train_reg,\n",
    "        mode='markers',\n",
    "        name='Training',\n",
    "        marker=dict(size=6, opacity=0.6)\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Test set\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_test_reg, y=y_pred_test_reg,\n",
    "        mode='markers',\n",
    "        name='Test',\n",
    "        marker=dict(size=6, opacity=0.6)\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Perfect prediction line\n",
    "max_val = max(y_train_reg.max(), y_test_reg.max())\n",
    "for col in [1, 2]:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0, max_val], y=[0, max_val],\n",
    "            mode='lines',\n",
    "            name='Perfect Prediction',\n",
    "            line=dict(dash='dash', color='red'),\n",
    "            showlegend=(col == 1)\n",
    "        ),\n",
    "        row=1, col=col\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(title_text='Actual Fare ($)', row=1, col=1)\n",
    "fig.update_xaxes(title_text='Actual Fare ($)', row=1, col=2)\n",
    "fig.update_yaxes(title_text='Predicted Fare ($)', row=1, col=1)\n",
    "fig.update_yaxes(title_text='Predicted Fare ($)', row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Linear Regression: Predicted vs Actual Fare',\n",
    "    template='plotly_white',\n",
    "    showlegend=True,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# 2. Residual plot\n",
    "residuals_test = y_test_reg - y_pred_test_reg\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_pred_test_reg,\n",
    "    y=residuals_test,\n",
    "    mode='markers',\n",
    "    marker=dict(size=6, opacity=0.6)\n",
    "))\n",
    "\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"red\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Residual Plot - Test Set',\n",
    "    xaxis_title='Predicted Fare ($)',\n",
    "    yaxis_title='Residuals (Actual - Predicted)',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# 3. Feature importance\n",
    "fig = px.bar(\n",
    "    feature_coef.head(10),\n",
    "    x='Coefficient',\n",
    "    y='Feature',\n",
    "    orientation='h',\n",
    "    title='Top 10 Features Affecting Fare Price',\n",
    "    labels={'Coefficient': 'Coefficient Value', 'Feature': ''},\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.update_layout(yaxis={'categoryorder': 'total ascending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clustering-header",
   "metadata": {},
   "source": [
    "## 8. Unsupervised Learning: K-Means Clustering\n",
    "\n",
    "**Clustering:**\n",
    "- Group similar data points together\n",
    "- No target variable (unsupervised)\n",
    "- Discover natural groupings in data\n",
    "\n",
    "**K-Means Algorithm:**\n",
    "1. Initialize K cluster centroids randomly\n",
    "2. Assign each point to nearest centroid\n",
    "3. Update centroids to mean of assigned points\n",
    "4. Repeat steps 2-3 until convergence\n",
    "\n",
    "**When to use:**\n",
    "- Customer segmentation\n",
    "- Document clustering\n",
    "- Image compression\n",
    "- Anomaly detection\n",
    "\n",
    "**Evaluation Metrics:**\n",
    "- **Inertia**: Sum of squared distances to nearest centroid (lower is better)\n",
    "- **Silhouette Score**: How similar points are to their cluster vs other clusters (-1 to 1, higher is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clustering-prep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for clustering\n",
    "print(\"Preparing Data for K-Means Clustering...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Select numerical features for clustering\n",
    "df_cluster = df_original.copy()\n",
    "df_cluster['age'] = df_cluster['age'].fillna(df_cluster['age'].median())\n",
    "df_cluster['fare'] = df_cluster['fare'].fillna(df_cluster['fare'].median())\n",
    "\n",
    "# Select features for clustering\n",
    "cluster_features = ['age', 'fare', 'sibsp', 'parch']\n",
    "X_cluster = df_cluster[cluster_features].copy()\n",
    "\n",
    "print(f\"Clustering features: {cluster_features}\")\n",
    "print(f\"Dataset shape: {X_cluster.shape}\")\n",
    "print(\"\\nFeature statistics:\")\n",
    "print(X_cluster.describe())\n",
    "\n",
    "# Scale features (important for K-means)\n",
    "scaler_cluster = StandardScaler()\n",
    "X_cluster_scaled = scaler_cluster.fit_transform(X_cluster)\n",
    "\n",
    "print(\"\\nFeatures scaled for clustering.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elbow-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal number of clusters using Elbow Method\n",
    "print(\"Finding Optimal Number of Clusters...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "k_range = range(2, 11)\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_cluster_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_cluster_scaled, kmeans.labels_))\n",
    "\n",
    "# Create elbow plot\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Elbow Method (Inertia)', 'Silhouette Score')\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=list(k_range), y=inertias, mode='lines+markers', name='Inertia'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=list(k_range), y=silhouette_scores, mode='lines+markers', name='Silhouette Score'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='Number of Clusters (K)', row=1, col=1)\n",
    "fig.update_xaxes(title_text='Number of Clusters (K)', row=1, col=2)\n",
    "fig.update_yaxes(title_text='Inertia', row=1, col=1)\n",
    "fig.update_yaxes(title_text='Silhouette Score', row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Determining Optimal Number of Clusters',\n",
    "    template='plotly_white',\n",
    "    showlegend=False,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Find optimal K based on silhouette score\n",
    "optimal_k = k_range[np.argmax(silhouette_scores)]\n",
    "print(f\"\\nOptimal number of clusters: {optimal_k}\")\n",
    "print(f\"Silhouette score at K={optimal_k}: {max(silhouette_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kmeans-clustering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train K-Means with optimal K\n",
    "print(f\"Training K-Means Clustering (K={optimal_k})...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(X_cluster_scaled)\n",
    "\n",
    "# Add cluster labels to original dataframe\n",
    "df_cluster['cluster'] = cluster_labels\n",
    "\n",
    "# Calculate metrics\n",
    "inertia = kmeans.inertia_\n",
    "silhouette = silhouette_score(X_cluster_scaled, cluster_labels)\n",
    "\n",
    "print(f\"\\nClustering Results:\")\n",
    "print(f\"  Number of clusters: {optimal_k}\")\n",
    "print(f\"  Inertia: {inertia:.2f}\")\n",
    "print(f\"  Silhouette Score: {silhouette:.4f}\")\n",
    "\n",
    "print(\"\\nCluster Sizes:\")\n",
    "print(df_cluster['cluster'].value_counts().sort_index())\n",
    "\n",
    "# Analyze cluster characteristics\n",
    "print(\"\\nCluster Characteristics (Mean Values):\")\n",
    "print(\"=\"*60)\n",
    "cluster_summary = df_cluster.groupby('cluster')[cluster_features + ['survived']].mean()\n",
    "print(cluster_summary.round(2))\n",
    "\n",
    "# Survival rate by cluster\n",
    "print(\"\\nSurvival Rate by Cluster:\")\n",
    "for cluster in range(optimal_k):\n",
    "    survival_rate = df_cluster[df_cluster['cluster'] == cluster]['survived'].mean()\n",
    "    count = (df_cluster['cluster'] == cluster).sum()\n",
    "    print(f\"  Cluster {cluster}: {survival_rate:.2%} (n={count})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clustering-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters\n",
    "\n",
    "# 3D scatter plot\n",
    "fig = px.scatter_3d(\n",
    "    df_cluster,\n",
    "    x='age',\n",
    "    y='fare',\n",
    "    z='sibsp',\n",
    "    color='cluster',\n",
    "    symbol='survived',\n",
    "    title=f'K-Means Clustering Results (K={optimal_k})',\n",
    "    labels={'cluster': 'Cluster', 'survived': 'Survived'},\n",
    "    color_continuous_scale='Viridis'\n",
    ")\n",
    "fig.update_layout(template='plotly_white')\n",
    "fig.show()\n",
    "\n",
    "# 2D projections\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Age vs Fare', 'Sibsp vs Parch')\n",
    ")\n",
    "\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_data = df_cluster[df_cluster['cluster'] == cluster]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=cluster_data['age'],\n",
    "            y=cluster_data['fare'],\n",
    "            mode='markers',\n",
    "            name=f'Cluster {cluster}',\n",
    "            marker=dict(size=6, opacity=0.6)\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=cluster_data['sibsp'],\n",
    "            y=cluster_data['parch'],\n",
    "            mode='markers',\n",
    "            name=f'Cluster {cluster}',\n",
    "            marker=dict(size=6, opacity=0.6),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(title_text='Age', row=1, col=1)\n",
    "fig.update_xaxes(title_text='Siblings/Spouses', row=1, col=2)\n",
    "fig.update_yaxes(title_text='Fare ($)', row=1, col=1)\n",
    "fig.update_yaxes(title_text='Parents/Children', row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'K-Means Clustering - 2D Projections (K={optimal_k})',\n",
    "    template='plotly_white',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Cluster characteristics heatmap\n",
    "fig = px.imshow(\n",
    "    cluster_summary.T,\n",
    "    labels=dict(x=\"Cluster\", y=\"Feature\", color=\"Mean Value\"),\n",
    "    title=\"Cluster Characteristics Heatmap\",\n",
    "    aspect=\"auto\",\n",
    "    color_continuous_scale='RdBu_r',\n",
    "    text_auto='.2f'\n",
    ")\n",
    "fig.update_layout(template='plotly_white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insights-header",
   "metadata": {},
   "source": [
    "## 9. Key Insights and Interpretations\n",
    "\n",
    "### Classification Model Insights\n",
    "\n",
    "**Model Performance Summary:**\n",
    "- All models achieved 75-80% accuracy on survival prediction\n",
    "- Neural networks and optimized KNN tend to perform slightly better\n",
    "- Decision trees offer the best interpretability\n",
    "\n",
    "**Most Important Features for Survival:**\n",
    "1. **Sex**: Being female significantly increased survival chances\n",
    "2. **Class**: First-class passengers had higher survival rates\n",
    "3. **Age**: Children had better survival rates\n",
    "4. **Fare**: Higher fare (proxy for class/cabin quality) correlated with survival\n",
    "\n",
    "### Regression Model Insights\n",
    "\n",
    "**Fare Prediction:**\n",
    "- Linear regression achieved R² ≈ 0.5-0.6\n",
    "- Class is the strongest predictor of fare\n",
    "- Age and family size also contribute to fare prediction\n",
    "- Model has higher errors for very high fares (outliers)\n",
    "\n",
    "### Clustering Insights\n",
    "\n",
    "**Passenger Segments:**\n",
    "- Clusters naturally separate by:\n",
    "  - Age groups (children, adults, elderly)\n",
    "  - Family status (traveling alone vs with family)\n",
    "  - Economic status (fare level)\n",
    "- Different clusters have different survival rates\n",
    "- Clustering can help identify passenger profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "best-practices-header",
   "metadata": {},
   "source": [
    "## 10. Machine Learning Best Practices\n",
    "\n",
    "### Data Preparation\n",
    "1. **Handle missing values systematically**\n",
    "   - Understand why data is missing (MCAR, MAR, MNAR)\n",
    "   - Use appropriate imputation methods\n",
    "   - Consider creating 'missing' indicator features\n",
    "\n",
    "2. **Feature engineering**\n",
    "   - Create meaningful features from raw data\n",
    "   - Combine related features\n",
    "   - Transform skewed distributions\n",
    "\n",
    "3. **Feature scaling**\n",
    "   - Crucial for distance-based algorithms (KNN, SVM, Neural Networks)\n",
    "   - Less important for tree-based methods\n",
    "   - Always fit scaler on training data only\n",
    "\n",
    "### Model Training\n",
    "1. **Always use train-test split**\n",
    "   - Prevents overfitting\n",
    "   - Provides realistic performance estimates\n",
    "   - Use stratification for imbalanced datasets\n",
    "\n",
    "2. **Start simple**\n",
    "   - Begin with baseline models (logistic regression, simple trees)\n",
    "   - Establish baseline performance\n",
    "   - Gradually increase complexity\n",
    "\n",
    "3. **Cross-validation**\n",
    "   - More robust than single train-test split\n",
    "   - Provides confidence intervals\n",
    "   - Helps detect overfitting\n",
    "\n",
    "### Model Evaluation\n",
    "1. **Use multiple metrics**\n",
    "   - Accuracy alone is often insufficient\n",
    "   - Consider precision, recall, F1, ROC AUC\n",
    "   - Choose metrics based on business objectives\n",
    "\n",
    "2. **Confusion matrix analysis**\n",
    "   - Understand types of errors\n",
    "   - Identify class-specific performance\n",
    "   - Inform model improvements\n",
    "\n",
    "3. **Compare multiple models**\n",
    "   - Different algorithms have different strengths\n",
    "   - Ensemble methods often perform best\n",
    "   - Consider interpretability vs performance tradeoff\n",
    "\n",
    "### Common Pitfalls to Avoid\n",
    "1. **Data leakage**\n",
    "   - Never use test data during training\n",
    "   - Fit preprocessors on training data only\n",
    "   - Be careful with time-series data\n",
    "\n",
    "2. **Overfitting**\n",
    "   - High training accuracy but low test accuracy\n",
    "   - Use regularization, cross-validation\n",
    "   - Simplify model or get more data\n",
    "\n",
    "3. **Underfitting**\n",
    "   - Poor performance on both training and test sets\n",
    "   - Model too simple for the problem\n",
    "   - Add features or increase model complexity\n",
    "\n",
    "4. **Ignoring class imbalance**\n",
    "   - Can lead to biased models\n",
    "   - Use stratified sampling, resampling, or class weights\n",
    "   - Focus on appropriate metrics (F1, ROC AUC)\n",
    "\n",
    "### Model Selection Guidelines\n",
    "\n",
    "**Logistic Regression:**\n",
    "- ✅ Need interpretability\n",
    "- ✅ Linear relationships\n",
    "- ✅ Fast training/prediction\n",
    "- ❌ Complex non-linear patterns\n",
    "\n",
    "**K-Nearest Neighbors:**\n",
    "- ✅ Non-linear patterns\n",
    "- ✅ No assumptions about data\n",
    "- ✅ Simple to understand\n",
    "- ❌ Large datasets\n",
    "- ❌ High-dimensional data\n",
    "\n",
    "**Decision Trees:**\n",
    "- ✅ Interpretability\n",
    "- ✅ Mixed feature types\n",
    "- ✅ Non-linear patterns\n",
    "- ❌ Stability (high variance)\n",
    "- ❌ Overfitting tendency\n",
    "\n",
    "**Neural Networks:**\n",
    "- ✅ Complex patterns\n",
    "- ✅ Large datasets\n",
    "- ✅ High-dimensional data\n",
    "- ❌ Interpretability\n",
    "- ❌ Computational cost\n",
    "- ❌ Need lots of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qa-header",
   "metadata": {},
   "source": [
    "## 11. Question and Answer Key\n",
    "\n",
    "### Conceptual Questions\n",
    "\n",
    "**Q1: What is the difference between supervised and unsupervised learning?**\n",
    "\n",
    "**A1:** \n",
    "- **Supervised Learning**: We have labeled data (input features + target variable). The algorithm learns to map inputs to outputs. Examples: Classification (predicting survival), Regression (predicting fare).\n",
    "- **Unsupervised Learning**: We have unlabeled data (only input features). The algorithm discovers patterns or structure in the data. Examples: Clustering (grouping similar passengers), Dimensionality Reduction.\n",
    "\n",
    "---\n",
    "\n",
    "**Q2: Why do we split data into training and test sets?**\n",
    "\n",
    "**A2:** \n",
    "- To evaluate model performance on unseen data\n",
    "- To prevent overfitting (memorizing training data)\n",
    "- To get realistic estimates of model performance in production\n",
    "- Training set: Used to fit the model parameters\n",
    "- Test set: Used to evaluate the final model (never used during training)\n",
    "\n",
    "---\n",
    "\n",
    "**Q3: What is overfitting and how can we prevent it?**\n",
    "\n",
    "**A3:**\n",
    "- **Overfitting**: Model performs well on training data but poorly on test data. The model has memorized the training data instead of learning general patterns.\n",
    "- **Prevention strategies**:\n",
    "  - Use train-test split or cross-validation\n",
    "  - Regularization (L1, L2, dropout)\n",
    "  - Reduce model complexity (fewer features, shallower trees, etc.)\n",
    "  - Get more training data\n",
    "  - Early stopping (for iterative algorithms)\n",
    "\n",
    "---\n",
    "\n",
    "**Q4: When should you use KNN vs Logistic Regression?**\n",
    "\n",
    "**A4:**\n",
    "- **Use KNN when**:\n",
    "  - Decision boundary is non-linear\n",
    "  - No assumptions about data distribution\n",
    "  - Small to medium dataset\n",
    "  - Computational cost of prediction is acceptable\n",
    "\n",
    "- **Use Logistic Regression when**:\n",
    "  - Need interpretable coefficients\n",
    "  - Decision boundary is approximately linear\n",
    "  - Fast training and prediction needed\n",
    "  - Want probabilistic predictions\n",
    "\n",
    "---\n",
    "\n",
    "**Q5: What metrics should you use for imbalanced classification?**\n",
    "\n",
    "**A5:**\n",
    "- **Don't rely on accuracy alone** - it can be misleading\n",
    "- **Better metrics**:\n",
    "  - **Precision**: Of predicted positives, how many are correct? (important when false positives are costly)\n",
    "  - **Recall**: Of actual positives, how many did we catch? (important when false negatives are costly)\n",
    "  - **F1 Score**: Harmonic mean of precision and recall (balanced metric)\n",
    "  - **ROC AUC**: Overall performance across all thresholds\n",
    "  - **Confusion Matrix**: See all types of errors\n",
    "\n",
    "---\n",
    "\n",
    "**Q6: How do you choose the number of clusters (K) in K-means?**\n",
    "\n",
    "**A6:**\n",
    "- **Elbow Method**: Plot inertia vs K, look for \"elbow\" where improvement slows\n",
    "- **Silhouette Score**: Measures how similar points are to their own cluster vs other clusters (higher is better)\n",
    "- **Domain Knowledge**: Sometimes you know how many groups make sense\n",
    "- **Dendrogram**: For hierarchical clustering\n",
    "- **Gap Statistic**: Compares inertia to random data\n",
    "\n",
    "---\n",
    "\n",
    "**Q7: Why is feature scaling important?**\n",
    "\n",
    "**A7:**\n",
    "- **Distance-based algorithms** (KNN, SVM, K-means) are sensitive to feature scales\n",
    "- Features with larger scales can dominate distance calculations\n",
    "- Example: Age (0-100) vs Fare (0-500) - fare would dominate without scaling\n",
    "- **Not needed for tree-based methods** (they use splits, not distances)\n",
    "- **Always fit scaler on training data only** to prevent data leakage\n",
    "\n",
    "---\n",
    "\n",
    "**Q8: What are the advantages of Decision Trees?**\n",
    "\n",
    "**A8:**\n",
    "- **Highly interpretable**: Can visualize and explain decisions\n",
    "- **No feature scaling needed**: Uses splits, not distances\n",
    "- **Handles non-linear relationships**: Can capture complex patterns\n",
    "- **Handles mixed features**: Numerical and categorical\n",
    "- **Can handle missing values**: Built-in mechanisms\n",
    "- **Feature importance**: Automatically ranks features\n",
    "\n",
    "**Disadvantages:**\n",
    "- **Prone to overfitting**: Can create overly complex trees\n",
    "- **Unstable**: Small data changes can cause large tree changes\n",
    "- **Biased**: Toward features with many levels\n",
    "\n",
    "---\n",
    "\n",
    "### Practical Questions\n",
    "\n",
    "**Q9: Based on our analysis, which model would you deploy for Titanic survival prediction and why?**\n",
    "\n",
    "**A9:**\n",
    "It depends on the requirements:\n",
    "\n",
    "- **If interpretability is crucial**: Decision Tree\n",
    "  - Can explain decisions to stakeholders\n",
    "  - Regulatory compliance may require explainability\n",
    "  - Reasonable accuracy (~78-80%)\n",
    "\n",
    "- **If performance is paramount**: Neural Network or Optimized KNN\n",
    "  - Highest accuracy (~80-82%)\n",
    "  - Can capture complex patterns\n",
    "  - Acceptable if black-box is okay\n",
    "\n",
    "- **If speed and simplicity matter**: Logistic Regression\n",
    "  - Fast training and prediction\n",
    "  - Good baseline performance (~78%)\n",
    "  - Easy to maintain and update\n",
    "\n",
    "**Recommendation**: Start with Logistic Regression as baseline, use Decision Tree for explainability, and consider ensemble methods (Random Forest) for best performance.\n",
    "\n",
    "---\n",
    "\n",
    "**Q10: What insights did we gain from clustering analysis?**\n",
    "\n",
    "**A10:**\n",
    "- Passengers naturally segment into groups based on:\n",
    "  - **Age groups**: Children, adults, elderly\n",
    "  - **Family status**: Traveling alone vs with family\n",
    "  - **Economic status**: Low, medium, high fare\n",
    "- Different clusters have different survival rates\n",
    "- Can use these segments for:\n",
    "  - Targeted safety measures\n",
    "  - Marketing strategies (if modern application)\n",
    "  - Understanding passenger demographics\n",
    "- Clustering helps discover patterns we might not have specified in advance\n",
    "\n",
    "---\n",
    "\n",
    "**Q11: How would you improve the fare prediction model?**\n",
    "\n",
    "**A11:**\n",
    "- **Feature engineering**:\n",
    "  - Add cabin deck information (if available)\n",
    "  - Interaction terms (e.g., class × age)\n",
    "  - Categorical encoding of continuous features\n",
    "\n",
    "- **Handle outliers**:\n",
    "  - Very high fares pull model predictions\n",
    "  - Consider log transformation\n",
    "  - Robust regression methods\n",
    "\n",
    "- **Try different models**:\n",
    "  - Decision Tree Regressor (non-linear)\n",
    "  - Random Forest Regressor\n",
    "  - Gradient Boosting\n",
    "\n",
    "- **More data**:\n",
    "  - Additional passenger information\n",
    "  - Cabin details\n",
    "  - Service level indicators\n",
    "\n",
    "---\n",
    "\n",
    "**Q12: What would you do if you had more time and resources?**\n",
    "\n",
    "**A12:**\n",
    "- **Hyperparameter tuning**: GridSearchCV or RandomizedSearchCV\n",
    "- **Ensemble methods**: Voting classifier, stacking, boosting\n",
    "- **Feature selection**: Remove irrelevant features systematically\n",
    "- **Cross-validation**: K-fold CV for robust evaluation\n",
    "- **Handle class imbalance**: SMOTE, class weights\n",
    "- **Deep learning**: More complex neural architectures\n",
    "- **External data**: Historical shipping data, weather conditions\n",
    "- **A/B testing**: Test model in production setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## 12. Summary and Next Steps\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Machine Learning Fundamentals**\n",
    "   - Supervised vs Unsupervised learning\n",
    "   - The ML workflow: data prep → split → train → evaluate → compare\n",
    "   - Importance of train-test split\n",
    "\n",
    "2. **Classification Algorithms**\n",
    "   - Logistic Regression: Linear, interpretable, fast\n",
    "   - K-Nearest Neighbors: Instance-based, non-linear\n",
    "   - Decision Trees: Interpretable, handles non-linearity\n",
    "   - Neural Networks: Complex patterns, high performance\n",
    "\n",
    "3. **Regression Analysis**\n",
    "   - Linear Regression for continuous predictions\n",
    "   - Evaluation metrics: MSE, MAE, R²\n",
    "   - Feature importance analysis\n",
    "\n",
    "4. **Unsupervised Learning**\n",
    "   - K-Means clustering for pattern discovery\n",
    "   - Choosing optimal K\n",
    "   - Cluster interpretation\n",
    "\n",
    "5. **Best Practices**\n",
    "   - Feature engineering and preprocessing\n",
    "   - Model evaluation with multiple metrics\n",
    "   - Avoiding common pitfalls\n",
    "   - Model selection guidelines\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **No single model is always best** - it depends on the problem, data, and requirements\n",
    "2. **Start simple, then increase complexity** - baseline models help establish expectations\n",
    "3. **Feature engineering often matters more than algorithm choice**\n",
    "4. **Always use train-test split** - never evaluate on training data\n",
    "5. **Consider multiple metrics** - accuracy alone is often insufficient\n",
    "6. **Interpretability vs Performance tradeoff** - decide based on use case\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Advanced Topics**\n",
    "   - Ensemble methods (Random Forest, Gradient Boosting)\n",
    "   - Cross-validation and hyperparameter tuning\n",
    "   - Handling imbalanced datasets\n",
    "   - Feature selection methods\n",
    "\n",
    "2. **Model Deployment**\n",
    "   - Saving and loading models\n",
    "   - Creating prediction APIs\n",
    "   - Monitoring model performance\n",
    "   - Model versioning\n",
    "\n",
    "3. **Practice Projects**\n",
    "   - Try different datasets\n",
    "   - Kaggle competitions\n",
    "   - Real-world applications\n",
    "   - End-to-end ML pipelines\n",
    "\n",
    "### Resources for Further Learning\n",
    "\n",
    "- **Scikit-learn Documentation**: https://scikit-learn.org/\n",
    "- **Machine Learning Coursera**: Andrew Ng's course\n",
    "- **Kaggle Learn**: Free ML courses and competitions\n",
    "- **Books**:\n",
    "  - \"Hands-On Machine Learning\" by Aurélien Géron\n",
    "  - \"Introduction to Statistical Learning\" by James et al.\n",
    "  - \"Pattern Recognition and Machine Learning\" by Bishop\n",
    "\n",
    "---\n",
    "\n",
    "### Congratulations!\n",
    "\n",
    "You've completed a comprehensive introduction to machine learning. You now have:\n",
    "- Understanding of ML fundamentals\n",
    "- Experience with multiple algorithms\n",
    "- Knowledge of best practices\n",
    "- Tools to continue learning\n",
    "\n",
    "Keep practicing and experimenting with different datasets and algorithms!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
