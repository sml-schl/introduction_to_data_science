{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4: Data Preparation & Feature Engineering\n",
    "\n",
    "**Duration:** 90 minutes  \n",
    "**Dataset:** Titanic Passenger Data\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand data quality properties and the knowledge hierarchy\n",
    "- Distinguish structured vs unstructured data\n",
    "- Handle missing data using different strategies\n",
    "- Detect and handle outliers\n",
    "- Apply normalization techniques\n",
    "- Perform categorical encoding\n",
    "- Create new features through feature engineering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Data Loading (5 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "print(\"✓ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Titanic dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "print(f\"Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Data Quality Assessment (15 mins)\n",
    "\n",
    "### The Knowledge Hierarchy\n",
    "- **Data:** Raw facts (e.g., \"Age: 22\")\n",
    "- **Information:** Processed data (e.g., \"Average age is 29.7\")\n",
    "- **Knowledge:** Understanding patterns (e.g., \"Younger passengers had better survival rates\")\n",
    "- **Wisdom:** Applying knowledge (e.g., \"Prioritize evacuating children in emergencies\")\n",
    "\n",
    "### Exercise 2.1: Data Quality Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check for missing values\n",
    "# Hint: Use df.isnull().sum()\n",
    "\n",
    "missing_values = # YOUR CODE HERE\n",
    "print(\"Missing Values per Column:\")\n",
    "print(missing_values)\n",
    "print(f\"\\nTotal missing values: {missing_values.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize missing data\n",
    "# Create a heatmap showing where data is missing\n",
    "\n",
    "missing_data = df.isnull()\n",
    "fig = px.imshow(missing_data.T, \n",
    "                labels=dict(x=\"Passenger\", y=\"Feature\", color=\"Missing\"),\n",
    "                title=\"Missing Data Heatmap (White = Missing)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Structured vs Unstructured Data\n",
    "\n",
    "**Structured Data:** Organized in tables with rows and columns (like our Titanic dataset)  \n",
    "**Unstructured Data:** No predefined format (e.g., text, images, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Identify different data types in our dataset\n",
    "# Hint: Use df.dtypes\n",
    "\n",
    "print(\"Data Types:\")\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Separate numerical and categorical features\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"\\nNumerical features: {numerical_cols}\")\n",
    "print(f\"Categorical features: {categorical_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Handling Missing Data (20 mins)\n",
    "\n",
    "### Missing Data Mechanisms\n",
    "- **MCAR** (Missing Completely At Random): No pattern\n",
    "- **MAR** (Missing At Random): Related to other observed variables\n",
    "- **MNAR** (Missing Not At Random): Related to the missing value itself\n",
    "\n",
    "### Exercise 3.1: Analyze Missing Age Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate percentage of missing age values\n",
    "age_missing_pct = # YOUR CODE HERE (use df['age'].isnull().mean())\n",
    "print(f\"Missing age values: {age_missing_pct*100:.1f}%\")\n",
    "\n",
    "# Check if age is MCAR, MAR, or MNAR\n",
    "# Compare survival rates for passengers with/without age data\n",
    "has_age = df[df['age'].notnull()]['survived'].mean()\n",
    "no_age = df[df['age'].isnull()]['survived'].mean()\n",
    "\n",
    "print(f\"\\nSurvival rate (age known): {has_age*100:.1f}%\")\n",
    "print(f\"Survival rate (age missing): {no_age*100:.1f}%\")\n",
    "print(f\"\\nDifference: {abs(has_age - no_age)*100:.1f} percentage points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Based on the survival rate difference, is the missing age data MCAR, MAR, or MNAR?\n",
    "\n",
    "Your answer: ___________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Imputation Strategies\n",
    "\n",
    "Let's try different ways to fill in missing age values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 1: Mean imputation\n",
    "# TODO: Fill missing ages with the mean age\n",
    "df['age_mean_imputed'] = # YOUR CODE HERE (use df['age'].fillna())\n",
    "\n",
    "print(f\"Original mean age: {df['age'].mean():.2f}\")\n",
    "print(f\"After mean imputation: {df['age_mean_imputed'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 2: Median imputation\n",
    "# TODO: Fill missing ages with the median age\n",
    "df['age_median_imputed'] = # YOUR CODE HERE\n",
    "\n",
    "print(f\"Original median age: {df['age'].median():.2f}\")\n",
    "print(f\"After median imputation: {df['age_median_imputed'].median():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 3: Group-based imputation (by passenger class and sex)\n",
    "# TODO: Fill missing ages with the median age of the same class and gender\n",
    "df['age_group_imputed'] = df.groupby(['pclass', 'sex'])['age'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "\n",
    "print(\"\\nMedian age by class and gender:\")\n",
    "print(df.groupby(['pclass', 'sex'])['age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the distributions\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=df['age'], name='Original (with missing)', opacity=0.7))\n",
    "fig.add_trace(go.Histogram(x=df['age_mean_imputed'], name='Mean Imputed', opacity=0.7))\n",
    "fig.add_trace(go.Histogram(x=df['age_group_imputed'], name='Group Imputed', opacity=0.7))\n",
    "fig.update_layout(title='Comparison of Imputation Strategies',\n",
    "                  xaxis_title='Age',\n",
    "                  yaxis_title='Count',\n",
    "                  barmode='overlay')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Which imputation strategy preserves the distribution best? Why?\n",
    "\n",
    "Your answer: ___________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3: Handling Missing Cabin Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check missing cabin data\n",
    "cabin_missing_pct = # YOUR CODE HERE\n",
    "print(f\"Missing cabin values: {cabin_missing_pct*100:.1f}%\")\n",
    "\n",
    "# Create a binary feature: cabin_known (1 if cabin is known, 0 otherwise)\n",
    "df['cabin_known'] = # YOUR CODE HERE (use df['cabin'].notnull().astype(int))\n",
    "\n",
    "# Check if having cabin information correlates with survival\n",
    "print(\"\\nSurvival rate by cabin information:\")\n",
    "print(df.groupby('cabin_known')['survived'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Outlier Detection and Handling (20 mins)\n",
    "\n",
    "### Exercise 4.1: Detect Outliers Using IQR Method\n",
    "\n",
    "**IQR (Interquartile Range) Method:**\n",
    "- Q1 = 25th percentile\n",
    "- Q3 = 75th percentile\n",
    "- IQR = Q3 - Q1\n",
    "- Outliers: values < Q1 - 1.5×IQR or > Q3 + 1.5×IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Detect outliers in 'fare' using IQR method\n",
    "Q1 = # YOUR CODE HERE (use df['fare'].quantile(0.25))\n",
    "Q3 = # YOUR CODE HERE (use df['fare'].quantile(0.75))\n",
    "IQR = # YOUR CODE HERE\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"Q1: {Q1:.2f}\")\n",
    "print(f\"Q3: {Q3:.2f}\")\n",
    "print(f\"IQR: {IQR:.2f}\")\n",
    "print(f\"Lower bound: {lower_bound:.2f}\")\n",
    "print(f\"Upper bound: {upper_bound:.2f}\")\n",
    "\n",
    "# Identify outliers\n",
    "outliers = df[(df['fare'] < lower_bound) | (df['fare'] > upper_bound)]\n",
    "print(f\"\\nNumber of outliers: {len(outliers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a box plot to visualize outliers\n",
    "fig = # YOUR CODE HERE (use px.box())\n",
    "fig.update_layout(title='Fare Distribution with Outliers',\n",
    "                  yaxis_title='Fare (£)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2: Z-Score Method for Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate Z-scores for fare\n",
    "# Z-score = (value - mean) / standard deviation\n",
    "df['fare_zscore'] = # YOUR CODE HERE (use stats.zscore())\n",
    "\n",
    "# Identify outliers (|Z-score| > 3)\n",
    "outliers_zscore = df[np.abs(df['fare_zscore']) > 3]\n",
    "print(f\"Number of outliers (Z-score > 3): {len(outliers_zscore)}\")\n",
    "\n",
    "# Show the outliers\n",
    "print(\"\\nOutliers:\")\n",
    "print(outliers_zscore[['name', 'fare', 'pclass', 'fare_zscore']].sort_values('fare', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Should we remove these outliers? Why or why not?\n",
    "\n",
    "Your answer: ___________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.3: Isolation Forest for Multivariate Outlier Detection\n",
    "\n",
    "**Isolation Forest:** Machine learning algorithm that detects anomalies by isolating outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use Isolation Forest to detect outliers\n",
    "# Select numerical features for analysis\n",
    "features_for_outliers = ['age_group_imputed', 'fare', 'sibsp', 'parch']\n",
    "X = df[features_for_outliers].copy()\n",
    "\n",
    "# Create and fit Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "df['outlier'] = iso_forest.fit_predict(X)\n",
    "# -1 = outlier, 1 = normal\n",
    "\n",
    "print(f\"Number of outliers detected: {(df['outlier'] == -1).sum()}\")\n",
    "print(f\"Percentage: {(df['outlier'] == -1).mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers in 2D space (Age vs Fare)\n",
    "fig = px.scatter(df, x='age_group_imputed', y='fare', \n",
    "                 color=df['outlier'].map({1: 'Normal', -1: 'Outlier'}),\n",
    "                 title='Outlier Detection with Isolation Forest',\n",
    "                 labels={'color': 'Status'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Normalization & Standardization (15 mins)\n",
    "\n",
    "### Why Normalize?\n",
    "- Different features have different scales\n",
    "- Many ML algorithms perform better with normalized data\n",
    "- Prevents features with large values from dominating\n",
    "\n",
    "### Exercise 5.1: Min-Max Normalization (0-1 scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply Min-Max scaling to age and fare\n",
    "scaler_minmax = MinMaxScaler()\n",
    "\n",
    "df['age_normalized'] = scaler_minmax.fit_transform(df[['age_group_imputed']])\n",
    "df['fare_normalized'] = # YOUR CODE HERE (use scaler_minmax.fit_transform())\n",
    "\n",
    "print(\"Original values:\")\n",
    "print(df[['age_group_imputed', 'fare']].describe())\n",
    "print(\"\\nNormalized values (0-1 range):\")\n",
    "print(df[['age_normalized', 'fare_normalized']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.2: Z-Score Standardization (mean=0, std=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply Z-score standardization\n",
    "scaler_standard = StandardScaler()\n",
    "\n",
    "df['age_standardized'] = scaler_standard.fit_transform(df[['age_group_imputed']])\n",
    "df['fare_standardized'] = # YOUR CODE HERE\n",
    "\n",
    "print(\"Standardized values (mean≈0, std≈1):\")\n",
    "print(df[['age_standardized', 'fare_standardized']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs normalized vs standardized\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Box(y=df['fare'], name='Original Fare'))\n",
    "fig.add_trace(go.Box(y=df['fare_normalized'], name='Normalized Fare'))\n",
    "fig.add_trace(go.Box(y=df['fare_standardized'], name='Standardized Fare'))\n",
    "fig.update_layout(title='Comparison of Scaling Methods',\n",
    "                  yaxis_title='Value')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Categorical Encoding (10 mins)\n",
    "\n",
    "### Exercise 6.1: One-Hot Encoding\n",
    "\n",
    "Machine learning models need numerical input. We need to convert categorical variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply one-hot encoding to 'embarked' column\n",
    "# Hint: Use pd.get_dummies()\n",
    "\n",
    "embarked_encoded = # YOUR CODE HERE\n",
    "print(\"Original column:\")\n",
    "print(df['embarked'].value_counts())\n",
    "print(\"\\nOne-hot encoded:\")\n",
    "print(embarked_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Encode 'sex' column\n",
    "# Create a binary encoding: male=1, female=0\n",
    "df['sex_encoded'] = # YOUR CODE HERE (use df['sex'].map({'male': 1, 'female': 0}))\n",
    "\n",
    "print(\"Sex encoding:\")\n",
    "print(df[['sex', 'sex_encoded']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Feature Engineering (15 mins)\n",
    "\n",
    "### Creating New Features\n",
    "\n",
    "Feature engineering is the art of creating new features from existing data to improve model performance.\n",
    "\n",
    "### Exercise 7.1: Family Size Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create family_size feature\n",
    "df['family_size'] = # YOUR CODE HERE (SibSp + Parch + 1)\n",
    "\n",
    "# Create is_alone feature\n",
    "df['is_alone'] = # YOUR CODE HERE (1 if family_size==1, else 0)\n",
    "\n",
    "print(\"Family size distribution:\")\n",
    "print(df['family_size'].value_counts().sort_index())\n",
    "print(f\"\\nPassengers traveling alone: {df['is_alone'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze survival by family size\n",
    "family_survival = df.groupby('family_size')['survived'].mean()\n",
    "fig = px.bar(x=family_survival.index, y=family_survival.values,\n",
    "             title='Survival Rate by Family Size',\n",
    "             labels={'x': 'Family Size', 'y': 'Survival Rate'})\n",
    "fig.update_layout(yaxis_tickformat='.0%')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.2: Extract Title from Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract title from name (Mr., Mrs., Miss., etc.)\n",
    "df['title'] = df['name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "print(\"Titles found:\")\n",
    "print(df['title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Group rare titles into 'Other'\n",
    "# Keep only common titles: Mr, Miss, Mrs, Master\n",
    "common_titles = ['Mr', 'Miss', 'Mrs', 'Master']\n",
    "df['title_grouped'] = df['title'].apply(\n",
    "    lambda x: x if x in common_titles else 'Other'\n",
    ")\n",
    "\n",
    "print(\"\\nGrouped titles:\")\n",
    "print(df['title_grouped'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze survival by title\n",
    "title_survival = df.groupby('title_grouped')['survived'].mean().sort_values(ascending=False)\n",
    "fig = px.bar(x=title_survival.index, y=title_survival.values,\n",
    "             title='Survival Rate by Title',\n",
    "             labels={'x': 'Title', 'y': 'Survival Rate'})\n",
    "fig.update_layout(yaxis_tickformat='.0%')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.3: Age Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create age groups\n",
    "# Categories: Child (0-12), Teen (13-19), Adult (20-59), Senior (60+)\n",
    "\n",
    "bins = [0, 12, 19, 59, 100]\n",
    "labels = ['Child', 'Teen', 'Adult', 'Senior']\n",
    "df['age_group'] = # YOUR CODE HERE (use pd.cut())\n",
    "\n",
    "print(\"Age group distribution:\")\n",
    "print(df['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival by age group\n",
    "age_group_survival = df.groupby('age_group')['survived'].mean()\n",
    "fig = px.bar(x=age_group_survival.index, y=age_group_survival.values,\n",
    "             title='Survival Rate by Age Group',\n",
    "             labels={'x': 'Age Group', 'y': 'Survival Rate'})\n",
    "fig.update_layout(yaxis_tickformat='.0%')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.4: Fare Per Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate fare per person (fare / family_size)\n",
    "df['fare_per_person'] = # YOUR CODE HERE\n",
    "\n",
    "print(\"Fare per person statistics:\")\n",
    "print(df['fare_per_person'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 8: Creating the Final Cleaned Dataset (10 mins)\n",
    "\n",
    "### Exercise 8.1: Select and Prepare Final Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create final dataset with cleaned and engineered features\n",
    "final_features = [\n",
    "    'survived',           # Target variable\n",
    "    'pclass',            # Original feature\n",
    "    'sex_encoded',       # Encoded feature\n",
    "    'age_group_imputed', # Imputed feature\n",
    "    'fare_per_person',   # Engineered feature\n",
    "    'family_size',       # Engineered feature\n",
    "    'is_alone',          # Engineered feature\n",
    "    'cabin_known'        # Engineered feature\n",
    "]\n",
    "\n",
    "df_final = df[final_features].copy()\n",
    "print(f\"Final dataset shape: {df_final.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check for any remaining missing values\n",
    "print(\"Missing values in final dataset:\")\n",
    "print(df_final.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\nFinal Dataset Summary:\")\n",
    "print(df_final.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary & Reflection\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "Today we learned:\n",
    "- ✓ How to assess data quality using the knowledge hierarchy\n",
    "- ✓ Strategies for handling missing data (mean, median, group-based imputation)\n",
    "- ✓ Multiple methods for detecting outliers (IQR, Z-score, Isolation Forest)\n",
    "- ✓ Normalization techniques (Min-Max, Z-score standardization)\n",
    "- ✓ Categorical encoding (one-hot encoding, binary encoding)\n",
    "- ✓ Feature engineering to create meaningful new features\n",
    "\n",
    "### Data Preparation Pipeline Summary\n",
    "\n",
    "```\n",
    "Raw Data → Missing Data Handling → Outlier Detection → \n",
    "Normalization → Encoding → Feature Engineering → Clean Dataset\n",
    "```\n",
    "\n",
    "### Reflection Questions\n",
    "\n",
    "1. Which imputation strategy worked best for the age variable and why?\n",
    "\n",
    "   Your answer: ___________________________________\n",
    "\n",
    "2. Why is feature engineering important for machine learning?\n",
    "\n",
    "   Your answer: ___________________________________\n",
    "\n",
    "3. What new feature did you find most insightful?\n",
    "\n",
    "   Your answer: ___________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus Challenge (Optional)\n",
    "\n",
    "### Create Your Own Feature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a new feature that you think might be useful\n",
    "# for predicting survival. Explain your reasoning!\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Analyze how your feature relates to survival\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Resources\n",
    "\n",
    "- **Scikit-learn Preprocessing:** https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- **Missing Data Handling:** https://pandas.pydata.org/docs/user_guide/missing_data.html\n",
    "- **Feature Engineering Guide:** https://www.kaggle.com/learn/feature-engineering\n",
    "\n",
    "**See you on Day 6 for Machine Learning!** 🤖"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
